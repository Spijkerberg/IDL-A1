{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P85YtYtdbElJ"
      },
      "outputs": [],
      "source": [
        "# !pip install tensorflow numpy\n",
        "# !pip install tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import Model, Input, Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
        "from tensorflow.keras.optimizers import Optimizer\n",
        "from tensorflow.keras.losses import Loss\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(\"Tensorflow version: \", tf.__version__)\n",
        "\n",
        "resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='')\n",
        "tf.config.experimental_connect_to_cluster(resolver)\n",
        "# This is the TPU initialization code that has to be at the beginning.\n",
        "tf.tpu.experimental.initialize_tpu_system(resolver)\n",
        "print(\"All devices: \", tf.config.list_logical_devices('TPU'))"
      ],
      "metadata": {
        "id": "f2Fd0f0DezUw",
        "outputId": "10847f5a-6c1d-424a-85d2-b233d550ec32",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensorflow version:  2.12.0\n",
            "All devices:  [LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:0', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:1', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:2', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:3', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:4', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:5', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:6', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:7', device_type='TPU')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import List, Dict, Literal, Tuple\n",
        "\n",
        "Kwargs = Dict[str, int | float | bool]\n",
        "Shape = Tuple[int,int]\n",
        "Layer = Tuple[str, Kwargs]\n",
        "Arch = Dict[str, List[Layer] | Shape]\n",
        "Data = Dict[str, np.ndarray]\n"
      ],
      "metadata": {
        "id": "j2_n-FMBfFJ9"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fashion MNIST, MLP"
      ],
      "metadata": {
        "id": "D0NSg5UX4luF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()\n",
        "y_train = tf.keras.utils.to_categorical(y_train)\n",
        "y_test = tf.keras.utils.to_categorical(y_test)\n",
        "\n",
        "plt.figure()\n",
        "plt.title(f\"image with label {y_train[0]}\")\n",
        "plt.imshow(x_train[0].reshape(28, 28), cmap='Greys')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "r3gyKKkdfUIT",
        "outputId": "1f8e3ad8-ee8b-4d9b-dcf9-f0facb05358b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        }
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def leaky_relu(x):\n",
        "    return tf.nn.leaky_relu(x, alpha=0.1)\n",
        "\n",
        "def build_model_from_arch(\n",
        "        arch,\n",
        "        optimizer: Optimizer = tf.keras.optimizers.Adadelta(),\n",
        "        loss: Loss = tf.keras.losses.categorical_crossentropy,\n",
        "        metrics: List[str] = [\"accuracy\"],\n",
        "        steps_per_execution: int = None,\n",
        "    ):\n",
        "    LAYER_DICT = {\n",
        "        'dense': Dense,\n",
        "        'dropout': Dropout,\n",
        "        'conv': Conv2D,\n",
        "        'maxpooling': MaxPooling2D,\n",
        "        'flatten': Flatten,\n",
        "    }\n",
        "    model: Model = Sequential()\n",
        "    model.add(Input(arch['shape'][0]))\n",
        "    for (layer, kwargs) in arch['layers']:\n",
        "        model.add(LAYER_DICT[layer](**kwargs))\n",
        "\n",
        "    model.add(Dense(arch['shape'][1], activation = 'softmax'))\n",
        "    model.compile(optimizer, loss, metrics, steps_per_execution)\n",
        "    return model\n",
        "\n",
        "mlp = {\n",
        "    'shape': (784, 10),\n",
        "    'layers': [\n",
        "        ('dense', {'units': 512, 'activation': leaky_relu}),\n",
        "        ('dropout', {'rate': 0.2}),\n",
        "        ('dense', {'units': 512, 'activation': leaky_relu}),\n",
        "        ('dropout', {'rate': 0.5}),\n",
        "    ]\n",
        "}\n",
        "\n",
        "cnn = {\n",
        "    'shape': ((28, 28, 1), 10),\n",
        "    'layers': [\n",
        "        ('conv', {'filters': 32,'kernel_size':(3, 3), 'activation': leaky_relu}),\n",
        "        ('conv', {'filters': 64,'kernel_size':(3, 3), 'activation': leaky_relu}),\n",
        "        ('maxpooling', {'pool_size': (2, 2)}),\n",
        "        ('dropout', {'rate': 0.25}),\n",
        "        ('flatten', {}),\n",
        "        ('dense', {'units': 128, 'activation': leaky_relu}),\n",
        "        ('dropout', {'rate': 0.5}),\n",
        "    ]\n",
        "}\n",
        "\n",
        "MLP = build_model_from_arch(mlp, tf.keras.optimizers.Adam(), steps_per_execution = 100)\n",
        "\n",
        "CNN = build_model_from_arch(cnn, tf.keras.optimizers.Adam(), steps_per_execution = 100)\n",
        "# MLP: tf.keras.Model = build_mlp_model(x_train.shape[1], y_train.shape[1])\n",
        "# # validation_split 0.1 is recommended for tuning hyper parameters\n",
        "# MLP.fit(x_train, y_train, batch_size=128, epochs=20, validation_split = 0.1, use_multiprocessing = True)"
      ],
      "metadata": {
        "id": "Uq3EHqNeCU76"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Model contains: Architecture, Regularisations, Optimizer, Losses, (Metrics)\n",
        "Testing may use: batch_size, epochs, validation_split (set at 0.1)\n",
        "'''\n",
        "\n",
        "def permute_fit_kwargses(\n",
        "        batch_sizes: List[int] = [128],\n",
        "        epochses: List[int] = [20],\n",
        "        verbose: int = 0,\n",
        "        validation_split: float = 0.1,\n",
        "    ) -> List[Kwargs]:\n",
        "    \"\"\"Provided with a list of `batch_sizes`, a list of number of epochs `epochses` generate all possible permutations of the inputs.\n",
        "    Will generate a list of the names, containing the specific kwargs\"\"\"\n",
        "    kwargses: List[Kwargs] = []\n",
        "    names: List[str] = []\n",
        "    for batch_size in batch_sizes:\n",
        "        for epochs in epochses:\n",
        "            kwargses.append({\n",
        "                \"batch_size\": batch_size,\n",
        "                \"epochs\": epochs,\n",
        "                \"verbose\": verbose,\n",
        "                \"validation_split\": validation_split,\n",
        "                })\n",
        "            names.append(f\"{batch_size=}, {epochs=}, {verbose=}, {validation_split=}\")\n",
        "    return kwargses, names\n",
        "\n",
        "def print_arch(arch: Arch):\n",
        "    result: str = ''\n",
        "    for key, value in arch.items():\n",
        "        result += f'arch.{key}={value}, '\n",
        "    return result + '\\n'\n",
        "\n",
        "def permute_models(\n",
        "    model_archs: List[Arch],\n",
        "    optimizers: List[Optimizer],\n",
        "    losses: List[Loss],\n",
        "    metrics: List[str] = [\"accuracy\"],\n",
        "    steps_per_execution: int = None,\n",
        "    ) -> List[Model]:\n",
        "    \"\"\"Provided with a list of `model_archs`, a list of number of epochs `epochses` generate all possible permutations of the inputs.\n",
        "    Will generate a list of the names, containing the specific kwargs\"\"\"\n",
        "    models: List[Model] = []\n",
        "    names: List[str] = []\n",
        "    for arch in model_archs:\n",
        "        for optimizer in optimizers:\n",
        "            for loss in losses:\n",
        "                models.append(build_model_from_arch(arch, optimizer(), loss, metrics, steps_per_execution))\n",
        "                names.append(print_arch(arch) + f\"{optimizer.__name__=}, {loss.__name__=}, {metrics=}, {steps_per_execution=}\")\n",
        "    return models, names\n",
        "\n",
        "def print_best(performances: List[List], k: int = 5):\n",
        "    sorted_k = sorted(performances, key = lambda x: x[-1], reverse = True)[:k]\n",
        "    sorted_k = [ '[' + ', '.join(map(str, perf)) + ']' for perf in sorted_k]\n",
        "    print(*sorted_k, sep='\\n')\n",
        "\n",
        "def run_all_tests(\n",
        "    data: Data,\n",
        "    models: List[Model],\n",
        "    fit_kwargses: List[Kwargs],\n",
        "    log: bool = True,\n",
        "    show_k_best: bool = True,\n",
        "    k: int = 5,\n",
        "    ):\n",
        "    if log:\n",
        "        n_models = len(models)\n",
        "        n_kwargs = len(fit_kwargses)\n",
        "        n_tot = n_models * n_kwargs\n",
        "        i = 1\n",
        "        print(msg:=f\"Will run {n_models} models, {n_kwargs} kwargs. {n_tot} total.\")\n",
        "        print(\"=\"*len(msg))\n",
        "\n",
        "    if show_k_best:\n",
        "        performances: List[List[int, int, float]] = []\n",
        "\n",
        "    n_train = data['x_train'].shape[0]\n",
        "    n_test = data['x_test'].shape[0]\n",
        "    for m_id, model in enumerate(models):\n",
        "        for f_id, fit_kwargs in enumerate(fit_kwargses):\n",
        "            if log:\n",
        "                print(f\"Run {i} of {n_tot}: Model {m_id}, fit_kwargs {f_id}\")\n",
        "                model.summary()\n",
        "\n",
        "            # fit each model on the same data with the same settings\n",
        "            model.fit(data['x_train'].reshape(n_train, *model.input_shape[1:]),\n",
        "                      data['y_train'], **fit_kwargs)\n",
        "\n",
        "            # evaluate the fitted model\n",
        "            score = model.evaluate(data['x_test'].reshape(n_test, *model.input_shape[1:]),\n",
        "                                   data['y_test'], verbose = fit_kwargs['verbose'])\n",
        "            metric_fmt = [f\"\\tMetric {name}: {s:.3f}\" for s, name in zip(score, model.metrics_names)]\n",
        "            performances.append([m_id, f_id, *[s for s, m in zip(score, model.metrics_names) if m == 'accuracy']])\n",
        "\n",
        "            if log:\n",
        "                print('\\n'.join(metric_fmt), '\\n')\n",
        "                i += 1\n",
        "\n",
        "    if show_k_best:\n",
        "        print(\"Best performing: \")\n",
        "        print_best(performances, k)\n",
        "\n",
        "data = {\n",
        "    'x_train': x_train,\n",
        "    'y_train': y_train,\n",
        "    'x_test': x_test,\n",
        "    'y_test': y_test,\n",
        "}\n",
        "\n",
        "models, m_names = permute_models(\n",
        "    model_archs= [mlp, cnn],\n",
        "    optimizers = [tf.keras.optimizers.Adadelta,\n",
        "                  tf.keras.optimizers.Adam,\n",
        "                  tf.keras.optimizers.SGD],\n",
        "    losses = [tf.keras.losses.categorical_crossentropy],\n",
        "    steps_per_execution=100, # higher is quicker\n",
        ")\n",
        "\n",
        "kwargs, k_names = permute_fit_kwargses(\n",
        "    batch_sizes = [64, 128, 256],\n",
        "    epochses = [5, 10, 20],\n",
        "    # verbose=1, # uncomment if you want to see the epochs in real time\n",
        ")\n",
        "\n",
        "run_all_tests(data, models, kwargs, log=False, show_k_best=True, k=5)\n"
      ],
      "metadata": {
        "id": "GjhtryvJG0ml"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best = [\n",
        "    [1, 0],\n",
        "    [0, 0]\n",
        "]\n",
        "\n",
        "for m_id, k_id in best:\n",
        "    print(m_names[m_id], k_names[k_id], sep = '\\n', end='\\n\\n')"
      ],
      "metadata": {
        "id": "jbzM2MoAzZfF",
        "outputId": "d2ef4c4d-a67d-482b-c1ee-00093383ee65",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "arch.shape=((28, 28, 1), 10), arch.layers=[('conv', {'filters': 32, 'kernel_size': (3, 3), 'activation': <function leaky_relu at 0x7f8cf4d42170>}), ('conv', {'filters': 64, 'kernel_size': (3, 3), 'activation': <function leaky_relu at 0x7f8cf4d42170>}), ('maxpooling', {'pool_size': (2, 2)}), ('dropout', {'rate': 0.25}), ('flatten', {}), ('dense', {'units': 128, 'activation': <function leaky_relu at 0x7f8cf4d42170>}), ('dropout', {'rate': 0.5})], \n",
            "optimizer.__name__='Adadelta', loss.__name__='categorical_crossentropy', metrics=['accuracy'], steps_per_execution=100\n",
            "batch_size=256, epochs=5, verbose=0, validation_split=0.1\n",
            "\n",
            "arch.shape=(784, 10), arch.layers=[('dense', {'units': 512, 'activation': <function leaky_relu at 0x7f8cf4d42170>}), ('dropout', {'rate': 0.2}), ('dense', {'units': 512, 'activation': <function leaky_relu at 0x7f8cf4d42170>}), ('dropout', {'rate': 0.5})], \n",
            "optimizer.__name__='Adadelta', loss.__name__='categorical_crossentropy', metrics=['accuracy'], steps_per_execution=100\n",
            "batch_size=256, epochs=5, verbose=0, validation_split=0.1\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# small test for the run function\n",
        "\n",
        "def test_run():\n",
        "    models, m_names = permute_models(\n",
        "        model_archs= [mlp, cnn],\n",
        "        optimizers = [tf.keras.optimizers.Adadelta],\n",
        "        losses = [tf.keras.losses.categorical_crossentropy],\n",
        "        steps_per_execution=100, # higher is quicker\n",
        "    )\n",
        "\n",
        "    kwargs, k_names = permute_fit_kwargses(epochses=[5])\n",
        "\n",
        "    run_all_tests(data, models, kwargs)\n",
        "\n",
        "test_run()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5PeTjGsC2t83",
        "outputId": "9d9a68d3-8e6f-43e4-bba6-b43aa0ae8e3a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[]\n",
            "Will run 1 models, 1 kwargs. 1 total.\n",
            "=====================================\n",
            "Run 1 of 1: Model 0, fit_kwargs 0\n",
            "\tMetric loss: 0.629\n",
            "\tMetric accuracy: 0.745 \n",
            "\n",
            "Best performing: \n",
            "[0, 0, 0.7447999715805054]\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": []
    },
    "accelerator": "TPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}